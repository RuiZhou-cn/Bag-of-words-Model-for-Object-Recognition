{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd18a518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "#img = cv.imread('home.jpg')\n",
    "\n",
    "img = cv.imread(\"C:\\\\Users\\\\rain\\\\Pictures\\\\B0006674.jpg\")\n",
    "img = cv.resize(img, (400, 400), interpolation=cv.INTER_AREA)\n",
    "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "\n",
    "img = cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "cv.imwrite('sift_keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ca81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist(vecA, vecB):\n",
    "    return np.sqrt(np.sum(np.power(vecA - VecB, 2)))\n",
    "def k_means(data, k):\n",
    "    # Initialization of k mean vectors\n",
    "    cluster_belong = np.zeros(data.shape[0],int)\n",
    "    mean_vectors = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(k):\n",
    "        rn = random.randint(0,data.shape[0])\n",
    "        mean_vectors[k] = data[rn,:].copy()\n",
    "    #\n",
    "    go_on = True\n",
    "    while(go_on):\n",
    "        go_on = False\n",
    "        \n",
    "        #Assign each point to one cluster\n",
    "        for i in range(data.shape[0]):\n",
    "            last_cluster_belong = cluster_belong[i]\n",
    "            min_dist = calc_dist(mean_vectors[0], data[i])\n",
    "            cluster_belong[i] = 0\n",
    "            for j in range(1, k):\n",
    "                if calc_dist(mean_vectors[j], data[i]) < min_dist:\n",
    "                    min_dist = calc_dist(mean_vectors[j], data[i])\n",
    "                    cluster_belong[i] = j\n",
    "            # if the cluster of any point changes, continue with the next iteration\n",
    "            if last_cluster_belong != cluster_belong[i]:\n",
    "                go_on = True\n",
    "        # Update the mean vectors of newly generated clusters\n",
    "        for i in range(k):\n",
    "            a = np.where(cluster_belong == i)\n",
    "            total = np.zeros(data.shape[1], )\n",
    "            average = np.zeros(data.shape[1], )\n",
    "            for j, index in enumerate(a[0]):\n",
    "                total += data[index]\n",
    "                average = (total/(j+1))\n",
    "            mean_vectors[i] = average.copy()\n",
    "    return [mean_vectors, cluster_belong]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65dfbf48",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3548017481.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [3], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    def bags_of_word(images)\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def bags_of_word(images)\n",
    "    img_features = SIFT(images) # [img_num, feature_num, feature_dim]\n",
    "    img_features_resize = np.resize(img_features,\\\n",
    "                                   (img_features.shape[0]*img_features.shape[1], img_features.shape[-1]))\n",
    "    mean_vectors, cluster_belong = k_means(img_features, k)\n",
    "    cluster_belong = np.resize(cluster_belong,\\\n",
    "                              (img_features.shape[0], img_features.shape[1]))\n",
    "    histograms = np.zeros(img_features.shape[0], int)\n",
    "    for idx, img inenumerate(cluster_belong):\n",
    "        statistic = Counter(img) # represent the image with a histogram over all clusters\n",
    "        for cluster in statistic:\n",
    "            histograms[idx,clluster] = statistic[cluster]\n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e5fa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn import svm\n",
    "import joblib\n",
    "import scipy.io\n",
    "WORD_COUNT = 50\n",
    "\n",
    "# compute SIFT Features of an image using opencv\n",
    "def calcSiftFeature(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # 计算图片的特点和特征点描述\n",
    "    keypoints, features = sift.detectAndCompute(img, None)\n",
    "    return features\n",
    "\n",
    "# 计算词袋\n",
    "def learnVocabulary(features):\n",
    "    # criteria表示迭代停止的模式 eps-精度0.1， max_iter-满足最大迭代次数20\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.1)\n",
    "    # 得到k-means聚类的初始中心点\n",
    "    flags = cv2.KEAMEANS_RANDOM_CENTERS\n",
    "    # 标签，中心 = keameans(输入数据（特征）、聚类的个数k，预设标签，聚类停止条件，重复聚类次数，初始聚类中心点)\n",
    "    compactness, labels, centers = cv2.kmeans(features, WORD_COUNT, None, criteria, 20, flags)\n",
    "    return centers\n",
    "\n",
    "# 计算特征向量\n",
    "def calcFeatVec(features, centers):\n",
    "    featVec = np.zeros((1, WORD_COUNT))\n",
    "    for i in range(0, features.shape[0]):\n",
    "        # 第i张图片的特征点\n",
    "        fi = features[i]\n",
    "        diffMat = np.tile(fi, (WORD_COUNT, 1)) - centers\n",
    "        # axis=1按行求和，即特征到每个中心点的距离\n",
    "        sqSum = (diffMat**2).sum(axis=1)\n",
    "        dist = sqSum**0.5\n",
    "        # 升序排序\n",
    "        sortedIndices = dist.argsort()\n",
    "        # 取出最小的距离，即找到最近的中心点\n",
    "        idx = sortedIndices[0]\n",
    "        # 该中心点对应+1\n",
    "        featVec[0][idx] += 1\n",
    "    return featVec\n",
    "\n",
    "# 训练svm分类器\n",
    "def SVM_Train(data_vec, labels):\n",
    "    # 设置SVM模型参数\n",
    "    clf = svm.SVC(decision_function_shape='ovo')\n",
    "    # 利用x_train,y_train训练SVM分类器，获得参数\n",
    "    clf.fit(data_vec,labels)\n",
    "    return clf\n",
    "\n",
    "# SVM分类器测试集正确率\n",
    "def SVM_Test(svm_model,centers,images_dir,features_dir):\n",
    "    # 计算每张图片的特征向量\n",
    "    data_vec,labels = cal_vec(images_dir, centers, features_dir)\n",
    "    res = svm_model.predict(data_vec)\n",
    "    num_test = data_vec.shape[0]\n",
    "    acc = 0\n",
    "    for i in range(num_test):\n",
    "        if labels[i] == res[i]:\n",
    "            acc = acc + 1\n",
    "    return acc/num_test,res,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b43d052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
